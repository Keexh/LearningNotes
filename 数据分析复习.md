# 数据分析复习 - 统计学基础知识

## 对比描述统计学和推断统计学

描述统计学（descriptive statistics）：是以某种便于提供信息的方法对数据进行整理、概括和展示的方法。详细来讲，描述统计学包括如何获取研究所需要的数据、如何通过对数据的汇总、 概括与分析并得出所关心的数据的特征、以及如何采用图表（charts）形式对数据进行处理和展示。 

推断统计学（inferential statistics）：是在样本基础上对总体的某些性质进行估计的方法，主要关注如何从总体（population）中抽取的样本（sample）去发现总体的某些特征。这里的总体可以由个人（individuals）组成，也可以由（objects）组成。推断统计学主要包括参数估计和假设检验。

- 参数估计（parameter estimation）是指利用样本信息推断所关心的总体特征；
- 假设检验（hypothesis testing），是用来判断样本与样本、样本与总体的差异是由抽样误差引起还是本质差别造成的统计推断方法（利用样本信息判断对总体的某个建设是否成立）。

## 统计变量类型

变量有两个基本类型：定性变量和定量变量。区别是能否用直接采用数值表示。

如果研究的特征是非数值的，则称作定性变量（qualitative variable）或者属性变量（attribute variable）；反之，研究的特征是数值的，则称作定量变量（quantitative variable）。

定性变量可视为分类/范畴（categorical）、离散变量或者因子（factor）。

定量变量可以分为离散型和连续型。

- 离散变量（discrete variable）只能取某些存在“间隙”的特定的值，通常通过计数得到。

- 连续变量（continuous variable）是指观测值可以取某个区间内的任意值。

## 统计测量尺度

测量尺度分为4种，分别是名义尺度、顺序尺度、间隔尺度和比率尺度。另一种说法是定类尺度、定序尺度、定距尺度和定比尺度。

- 名义尺度（nominal level）：数据类别用标记或者名称表示，只能进行分类处理；即使对标签指定了相应的数值，不同类型之间也不存在逻辑顺序。
- 顺序尺度（ordinal level）：数据类别用一组标记或者名称（e.g. 高、中、低）表示，这些标记或名称有相对数值，因此可以被分为等级或者被排序。
- 间隔尺度（interval level）：不同数值的差有意义，而比值无意义，就会采用间隔尺度测量（e.g. 衣服尺码、温度计）。间隔尺度的性质：分类数据根据它们具有的数量特征进行排序；相同的测量值之间的差对应着相同的数量特征差。
- 比率尺度（ratio level）：所有的定量数据都是比率尺度数据。比率尺度具有间隔尺度的全部特征，而且0点（表示数量特征不存在）和两个数值之比具有实际意义。

## 常用统计类型划分

统计类型分为3类，分别是横截面数据、时间序列数据和面板数据。

- 横截面数据（cross-sectional data）：横截面数据是指在某一时点收集的不同对象的数据。它对应同一时点上不同空间(对象)所组成的一维数据集合，研究的是某一时点上的某种经济现象，突出空间 (对象)的差异。
- 时间序列数据（time series data）：是在不同时间上收集到的数据，用于所描述现象随时间变化的情况。这类数据反映了某一事物、现象等随时间的变化状态或程度（发展规律）。时间序列数据是同一统一指标按时间顺序记录的数据列。在同一数据列中的各个数据必须是同口径的，要求具有可比性。时序数据可以是时期数，也可以时点数。
- 面板数据（panel data）：是指在时间序列上取多个截面，在这些截面上同时选取样本观测值所构成的样本数据。或者说它是一个 $m \times n$ 的数据矩阵，记载的是$n$个时间节点上，$m$个对象的某一数据指标。

## 常见频数分布

- 钟形分布（bell-shaped distribution/mound-shaped distribution）。 其特征是“两头小， 中间大”， 即靠近中间的变量值分布的次数多， 靠近两端的变量值分布次数少， 其曲线如一口古钟。 钟形分布包括正态分布和偏态分布；
- U 型分布（U-shaped distribution）。 其特征是“两头大， 中间小”， 即靠近中间的变量值分布的次数少， 靠近两端的变量值分布次数多；
-  J 型分布（J-shaped distribution）。 J 型分布有两种， 一种是次数随着变量的增大而增多， 呈正 J 型； 另一种是次数随着变量的增加而减少， 呈反 J 型。

## 频数相关术语

- 组频数（class frequency）
- 相对组频数（relative class frequency）
- 组中值（class midpoint）
- 组距（class interval）
- 累计频数（cumulative frequency）

## 常见图表中英文

- 条形图（bar chart）

- 直方图（histogram）

- 饼图（pie chart）

- 折线图（polygon）

- 点状图（dot plot）

- 茎叶图（stem-and-leaf display）

- 箱型图（box plot）：包含$min,\ Q_1,\ median, \ Q_3, \ max$

- 散点图（scatter plot）
- 树状图（tree diagram）

## 常用统计描述用词

- 穷举的（exhaustive）：每个观测值必须落在某一个类中。
- 互不相容（mutually exclusive）：一组类别的性质，如果能够使得每个个体、对象或者度量只属于其中某一个类别。

## 数值度量

### 位置度量

位置度量（measures of location）：通常指平均数（average），还包括算术平均数、加权平均数、中位数、众数、几何平均数。

- 算术平均数（arithmetic mean）：$M=\displaystyle \frac{1}{n} \sum_{i=1}^{n} x_i$
- 加权算术平均数（weighted arithmetic mean）：$M_f=\displaystyle \frac{\displaystyle\sum_{i=1}^{n}x_{i}f_{i}}{\displaystyle\sum_{i=1}^{n}f_{i}}$
- 几何平均数（geometric mean）：$GM=(\displaystyle \prod_{i=1}^{n}x_i)^{\frac{1}{n}}$ 用于计算百分比、比率、指数或增长率的平均变动
- 调和平均数（harmonic mean）：$H=\displaystyle \frac{n}{\displaystyle \sum_{i=1}^{n}\frac{1}{x_i}}$，将所有数值取倒数并求其算术平均数后，再将此算术平均数取倒数而得，一般用于计算平均速率。
- 中位数（median）、四分位数（quartiles）、十分位数（deciles）、百分位数（percentiles）：$L_P=\displaystyle(n+1)\frac{P}{100}$，不一定是一组数据中的实际数值。
- 众数（mode）

### 离散程度度量

离散程度度量（measures of dispersion），也被称为变异程度（variation）和离中趋势（spread），常见的有：极差、平均离差、方差、标准差。

- 极差/全距（range）：$R =x_{max}-x_{min}$
- 平均离差（mean deviation）：$M_D=\displaystyle \frac{1}{n} \sum_{i=1}^{n} |x_i-\bar{x}|$
- 方差（variance）：总体方差用 $\sigma^2=\displaystyle \frac{\sum(X-\mu)^2}{N}$表示，$X$表示总体中观测值的数值，$\mu$表示总体的算术平均值，$N$表示总体中观测值的个数。样本方差用 $s^2=\displaystyle \frac{\sum(X-\bar{X})^2}{n-1}$表示，$X$表示总体中观测值的数值，$\bar{X}$表示样本均值，$n$表示样本中观测值的个数。
  - 在概率论中，方差用于度量随机变量和其数学期望（均值）之间的偏离程度。
  - 期望（Expected Value）是试验中每次可能的结果乘以其结果概率的总和。
- 标准差（standard deviation）：总体标准差 $\sigma=\displaystyle\sqrt{\frac{\sum(X-\mu)^2}{N}}$，样本标准差 $s=\displaystyle \sqrt{\frac{\sum(X-\bar{X})^2}{n-1}}$
- 变异系数（coefficient of variation）：总体：$c_v=\sigma/\mu$ ，样本$c_v=S/\bar{X}$。

#### 为什么样本方差分母是$n-1$？

如果用$n$代替$N$，在逻辑上是正确的，但这样会低估总体方差$\sigma ^2$。利用$n-1$作为分母对这种低估趋势提供适当修正。

#### 切比雪夫定理和经验法则

- 切比雪夫定理（Chebyshev's Theorem）：对于任意一组观测值（总体或者样本）落在均值加上$k$个标准差和均值减去$k$个标准差的区间之内的数值比例至少为$1-1/k^2$，其中$k$是任意大于1的常数。切比雪夫定理适用于观测值的分布呈现任意形状。举例：至少有24/25或96%的数值必定落在均值$\pm5$个标准差的区间内。
- 经验法则（empirical rule）或者正态法则（normal rule）：对于一个对称的钟型分布，大约68%的观测值落在均值加减1个标准差的区间内；大约95%的观测值落在均值加减2个标准差的区间内；几乎全部（大约99.7%）的观测值落在均值加减3个标准值的区间内（可以用于剔除离群值）。

#### 为什么要计算变异系数？

计算变异系数可以消除变量值水平高低和计量单位不同对离散程度测度值的影响  ，不能用于平均值为零的情况，且只对由比率标量计算出来的数值有意义（间隔尺度或区间标量，如温度区间，所得到的变异系数没有意义）。

## 分布形状 

- 对称的（symmetric）：均值和中位数相同
- 右偏的（skewed to the right）/正偏的（positively skewed）：均值大于中位数
- 左偏的（skewed to the light）/正偏的（negatively skewed）：均值小于中位数
- 双峰的（bimodal）：具有两个及以上的分布

## 以正态分布为比较标准的变异指标

- 偏度系数（coefficient of skewness）：对称分布，偏度为0，否则要么左偏要么右偏。皮尔逊偏度系数：$sk=\displaystyle \frac{3(\bar{X}-M)}{s}$， M是中位数，s是标准差，值域是[-3, 3]。统计软件偏度系数公式：$\displaystyle sk=\frac{n}{(n-1)(n-2)}\displaystyle [\sum(\frac{X-\bar{X}}{s})^3]$
- 峰度系数

## 标准分数/Z分数



# 机器学习与统计

## 不同专业领域对输入输出的称呼

- 输入（input）= 预测子（predictor）= 自变量（independent variable）

- 输出（output） = 响应（response） = 因变量（dependent variable）

- 错误率（error rate），精度（accuracy）= 1 - 错误率

- 误差（error）：模型预测输出和真实输出的差异；训练集上的误差为训练误差（training error）或经验误差（emprical error）；在新样本上的误差为泛化误差（generalization error）。选用的模型或者学习期应该是泛化误差要尽可能的小。

- 过拟合（overfitting）或过配：把训练样本自身特点当作全部潜在样本都具有的一般性质，会导致泛化误差增大（泛化性能下降）。E.g. 判断是否为叶子，训练样本叶子都有锯齿，当给予无锯齿的叶子时将其判断为不是叶子。过拟合是无法彻底避免的，产生的原因有：

  - 训练集和测试集特征分布不一致

  - 数据噪声太大

  - 数据量太小

  - 特征量太多

  - 模型太复杂

    常见的解决办法有：

  - 减少特征数量

  - 正则化

  - 增大样本训练规模

  - 简化模型

  - 交叉验证

  - drop-out

- 欠拟合（underfitting）或欠配：对训练样本的一般性质尚未学好。E.g. 判断是否为叶子，只学会了绿色，因而把整颗树都判断为叶子。欠拟合一般是因为学习能力低下导致的，如模型复杂度过低、特征数量较少等；相应的解决办法如在决策树学习中拓展分支、在神经网络学习中增加训练轮数等。

- 测试误差（testing error）：是用模型测试样本等判别能力，得到的测试误差作为泛化误差等近似。

- 模型选择（model selection）是评估泛化误差的过程。

- 将一个数据集$D$划分为训练集$S$和测试集$T$的方法：

  - 留出法（hold-out）：$D=S\cup T,\ S\cap T=\varnothing$，在S上训练出模型后，用T来评估测试误差来作为泛化误差的估计。一般采用分层采样（stratified sampling）保持数据分布的一致性。需要采用多次随机划分产生不同的S和T得出多个测试误差，再求取均值。为了使模型更接近于$D$的实际情况，需要保证$S$有足够样本，同时为了使评估结果稳定准确也需要有合适大小的$T$作为测试集。从偏差-方差的角度理解，测试集小时，评估结果方差较大；训练集小时，评估结果的偏差较大。常见处理办法是按照$2:1$～$4:1$划分$S$和$T$，或者$S$占$D$的2/3 ～4/5。

    ```python
    # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split
    # https://scikit-learn.org.cn/view/649.html
    >>> from sklearn.model_selection import train_test_split
    >>> X, y = np.arange(10).reshape((5, 2)), range(5)
    >>> X
    array([[0, 1],
           [2, 3],
           [4, 5],
           [6, 7],
           [8, 9]])
    >>> list(y)
    [0, 1, 2, 3, 4]
    >>> X_train, X_test, y_train, y_test = train_test_split(
    ...     X, y, test_size=0.33, random_state=42)
    ...
    >>> X_train
    array([[4, 5],
           [0, 1],
           [6, 7]])
    >>> y_train
    [2, 0, 3]
    >>> X_test
    array([[2, 3],
           [8, 9]])
    >>> y_test
    [1, 4]
    >>> train_test_split(y, shuffle=False)
    [[0, 1, 2], [3, 4]]
    ```

    | 参数             | 说明                                                         |
    | :--------------- | ------------------------------------------------------------ |
    | ***arrays**      | **sequence of indexables with same length / shape[0]** 允许的输入是列表，numpy数组，稀疏矩阵或padas中的DataFrame。 |
    | **test_size**    | **float or int, default=None** 如果为float，则应在0.0到1.0之间，表示要包括在测试集切分中的数据集的比例。如果为int，则表示测试集样本的绝对数量。如果为None，则将值设置为训练集大小的补集。如果`train_size`也是None，则将其设置为0.25。 |
    | **train_size**   | **float or int, default=None** 如果为float，则应在0.0到1.0之间，并表示要包含在训练集切分中的数据集的比例。如果为int，则表示训练集样本的绝对数量。如果为None，则该值将自动设置为测试集大小的补集。 |
    | **random_state** | **int or RandomState instance, default=None** 在应用切分之前，控制应用于数据的无序处理。为多个函数调用传递可重复输出的int值。请参阅[词汇表](http://scikit-learn.org.cn/lists/91.html#参数)。 |
    | **shuffle**      | **bool, default=True** 切分前是否对数据进行打乱。如果shuffle = False，则stratify必须为None。 |
    | **stratify**     | **array-like, default=None** 如果不为None，则以分层方式切分数据，并将其用作类标签。 |

    | 返回值        | 说明                                                         |
    | :------------ | :----------------------------------------------------------- |
    | **splitting** | **list, length=2 \* len(arrays)** 列表包含切分后的训练集和测试集  *版本0.16中的新功能*：如果输入稀疏，则输出将为`scipy.sparse.csr_matrix` 。否则，输出类型与输入类型相同。 |

    

  - 交叉验证法（cross validation）先将数据集$D$划分为$k$个大小相似的互斥子集，每个子集尽可能保持数据分布的一致性（通过分层采样获取）。每次用$k-1$个子集作为训练集，剩余的1个子集作为测试集，进行$k$次训练和测试，通常称为 k折交叉验证（k-fold cross validation）。$k$取值一般为10，5，20等。划分$k$个子集可以按照留出法那样划分$p$次，目的是减小因样本划分不同而引入的差别，最终评估$p$次$k$折交叉验证结果的均值。

    

    ```python
    # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html
    # https://scikit-learn.org.cn/view/639.html
    >>> import numpy as np
    >>> from sklearn.model_selection import LeaveOneOut
    >>> X = np.array([[1, 2], [3, 4]])
    >>> y = np.array([1, 2])
    >>> loo = LeaveOneOut()
    >>> loo.get_n_splits(X)
    2
    >>> print(loo)
    LeaveOneOut()
    >>> for train_index, test_index in loo.split(X):
    ...     print("TRAIN:", train_index, "TEST:", test_index)
    ...     X_train, X_test = X[train_index], X[test_index]
    ...     y_train, y_test = y[train_index], y[test_index]
    ...     print(X_train, X_test, y_train, y_test)
    TRAIN: [1] TEST: [0]
    [[3 4]] [[1 2]] [2] [1]
    TRAIN: [0] TEST: [1]
    [[1 2]] [[3 4]] [1] [2]
    
    ```

    | 方法                                 | 说明                                   |
    | :----------------------------------- | :------------------------------------- |
    | `get_n_splits`(self, X[, y, groups]) | 返回交叉验证器中的切分迭代次数         |
    | `split`(self, X[, y, groups])        | 生成索引以将数据切分为训练集和测试集。 |

  - 留一法（Leave-One-Out，LOO）是特殊的交叉验证。在$m$个样本中，进行$k=m$的交叉验证。每次只留下一个样本作为测试集，其余$m-1$个作为训练集。好处是实际评估的模型与期望评估的数据集$D$很相似；缺点是训练集特别大的时候计算开销会无比巨大（不考虑算法调参）。尽管看起来留一法很好，但是可能也没有其他评估方法有效。
  
  - 自助法（boostingrapping）可以保证模型规模贴近于$D$，并且不会有过大的计算复杂度。通过对$m$个样本对$D$随机有放回抽样$m$次，产生数据集$D\prime$。样本在经过$m$次采样中始终不被采样到的概率是$\displaystyle (1-\frac{1}{m})^m$，取极限得到$\displaystyle \frac{1}{e}\approx 0.368$。初始数据集中有36.6%的概率未被采样到$D\prime$中，因此我们可以将$D\prime$作为训练集（规模与初始数据一致），将$D \backslash D\prime$用作测试集。这种测试结果也称为包外估计（out-of-bag estimate）。一般情况，自助法在数据集较小、难以有效划分训练集/测试集时很有用，但自助法产生的数据集改变了初始数据分布，会引入估计偏差。当数据集样本足够时，留出法和交叉验证分常用。
  
  - 在模型选择完成后（经过模型评估和选择过程），学习算法和参数配置已选定，应用数据集$D$重新训练模型，这个模型才是最终模型。
  
  - 验证集（validation set）是模型评估与选择中评估测试的数据集，是将训练数据划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参。此时的测试集则被用于估计模型在实际使用时的泛化能力。
  
  - 衡量模型泛化能力的评价标准称为性能度量（performance measure）。性能度量得到的结果要结合算法、数据和具体任务目标来考虑。
  
  - 性能度量：
  
    - 回归任务：均方误差（mean square error，MSE）
  
  - 


# Tableau

